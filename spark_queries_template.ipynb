{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "181bbe29-26f4-4c4a-a9e9-0053263bff52",
   "metadata": {},
   "source": [
    "# Assignment: Scalable Processing\n",
    "## Yelp Reviews and Authenticity\n",
    "\n",
    "Large Scale Data Analysis / Big Data Management | by Tobias Lysdal Hansen | tolh@itu.dk | October 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92690678-bb97-43d7-ab27-4a6f8db87079",
   "metadata": {},
   "source": [
    "## Connecting to the Spark Cluster job using the two JobParameters.json\n",
    "\n",
    "To connect this jupyter notebook with your Spark cluster, we need to tell jupyter how it can access the spark cluster. Below code accomplishes that. Do not worry about how it works, just run the cell once to connect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d483a774-a0ca-4873-a2ee-51d2fcd30ead",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:14:42.451947Z",
     "iopub.status.busy": "2024-10-08T17:14:42.451527Z",
     "iopub.status.idle": "2024-10-08T17:15:08.022077Z",
     "shell.execute_reply": "2024-10-08T17:15:08.020811Z",
     "shell.execute_reply.started": "2024-10-08T17:14:42.451918Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell has not been executed before. Please restart the UCloud jobs if any error message pops up.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "alert(\"The JupyterLab job was started using spark hostname my-cluster. This is not recommended, please start it using spark-cluster instead\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "#####################################################################\n",
    "# DO NOT CHANGE ANYTHING HERE.\n",
    "# IF YOU HAVE PROBLEMS, CHECK THE ASSIGNMENT GUIDE CAREFULLY \n",
    "#####################################################################\n",
    "from IPython.display import Javascript, display\n",
    "import jupyterlab\n",
    "import os, json, pyspark\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.conf import SparkConf\n",
    "from py4j.protocol import Py4JJavaError\n",
    "\n",
    "\n",
    "def show_popup(message):\n",
    "    display(Javascript(f'alert(\"{message}\")'))\n",
    "\n",
    "def check_correct_file_location():\n",
    "    items = os.listdir('/work')\n",
    "    items_expected = ['yelp', 'Home','JobParameters.json']\n",
    "    if sorted(items) != sorted(items_expected):\n",
    "        notebook_location = os.getcwd()\n",
    "        items_to_be_moved = [item for item in items if item not in items_expected and item[0] != '.'] # Ignore hidden files starting with .\n",
    "        show_popup(f\"Warning: Found these files {items_to_be_moved} that should (most likely) be moved inside your Home folder. Make sure your Git repository and notebooks are all saved inside your Home folder and not at the 'root'/top of filesystem. Please move your files to prevent them from disappearing.\")\n",
    "    if 'yelp' not in items_expected:\n",
    "        show_popup(f'Error: the folder \"yelp\" does not seem to be accessible - did you remeber to add it to the Spark Cluster job and JupyterLab job?')\n",
    "    \n",
    "def job_timeout_warning(APP_NAME):\n",
    "    show_popup(f\"Warning: Your UCloud job {APP_NAME} will shut down in 2 minutes. Save your work and/or extend the job on https://cloud.sdu.dk/app/jobs to prevent data loss.\")\n",
    "    \n",
    "check_correct_file_location()\n",
    "\n",
    "SUPPORTED_SPARK_VERSION = \"3.3.1\"\n",
    "SUPPORTED_JUPYTERLAB_VERSION = \"3.5.1\"\n",
    "if jupyterlab.__version__ != SUPPORTED_JUPYTERLAB_VERSION:\n",
    "    show_popup(f\"Wrong JupyterLab version :( When starting the UCloud job you selected {jupyterlab.__version__} but it should have been {SUPPORTED_JUPYTERLAB_VERSION}\")\n",
    "    show_popup(\"Please shutdown this JupyterLab job and follow the instructions carefully in the UCloud setup guide PDF on LearnIT\") \n",
    "elif '_EXECUTED_' in globals(): # Only execute this cell once.\n",
    "    # check if variable '_EXECUTED_' exists in the global variable namespace\n",
    "    print(\"Already been executed once, not running again!\")\n",
    "else:\n",
    "    print(\"Cell has not been executed before. Please restart the UCloud jobs if any error message pops up.\")\n",
    "    # Two files are automatically read: JobParameters.json for the Spark Cluster job using a temporary spark instance\n",
    "    # and JobParameters.json for the Jupyter Lab job to extract the hostname of the cluster. \n",
    "\n",
    "    MASTER_HOST_NAME = None\n",
    "\n",
    "    # Open the parameters Jupyter Lab app was launched with\n",
    "    with open('/work/JobParameters.json', 'r') as file:\n",
    "        JUPYTER_LAB_JOB_PARAMS = json.load(file)\n",
    "        # from pprint import pprint; pprint(JUPYTER_LAB_JOB_PARAMS) \n",
    "        for resource in JUPYTER_LAB_JOB_PARAMS['request']['resources']:\n",
    "            if 'hostname' in resource.keys():\n",
    "                MASTER_HOST_NAME = resource['hostname']\n",
    "    \n",
    "    if MASTER_HOST_NAME != \"spark-cluster\":\n",
    "        show_popup(f\"The JupyterLab job was started using spark hostname {MASTER_HOST_NAME}. This is not recommended, please start it using spark-cluster instead\")\n",
    "    MASTER_HOST = f\"spark://{MASTER_HOST_NAME}:7077\"\n",
    "\n",
    "    conf = SparkConf().setAll([\n",
    "            (\"spark.app.name\", 'reading_job_params_app'), \n",
    "            (\"spark.master\", MASTER_HOST),\n",
    "        ])\n",
    "\n",
    "    spark = SparkSession.builder.config(conf=conf)\\\n",
    "                                .getOrCreate()\n",
    "    \n",
    "    if spark.version != SUPPORTED_SPARK_VERSION:\n",
    "        show_popup(f\"Wrong Spark Cluster version :( When starting the UCloud job you selected {spark.version} but it should have been {SUPPORTED_SPARK_VERSION}\")\n",
    "        show_popup(\"Please shutdown this JupyterLab job, the Spark Cluster and follow the instructions carefully in the UCloud setup guide PDF on LearnIT\") \n",
    "\n",
    "    CLUSTER_PARAMETERS_JSON_DF = spark.read.option(\"multiline\",\"true\").json('/work/JobParameters.json')\n",
    "    \n",
    "    # Extract cluster info from the specific JobParameters.json\n",
    "    NODES = CLUSTER_PARAMETERS_JSON_DF.select(\"request.replicas\").first()[0]\n",
    "    CPUS_PER_NODE = CLUSTER_PARAMETERS_JSON_DF.select(\"machineType.cpu\").first()[0] - 1\n",
    "    MEM_PER_NODE = CLUSTER_PARAMETERS_JSON_DF.select(\"machineType.memoryInGigs\").first()[0]\n",
    "\n",
    "    CLUSTER_CORES_MAX = CPUS_PER_NODE * NODES\n",
    "    CLUSTER_MEMORY_MAX = MEM_PER_NODE * NODES \n",
    "    \n",
    "    if CPUS_PER_NODE > 1:\n",
    "        EXECUTOR_CORES = CPUS_PER_NODE - 1  # set cores per executor on worker node\n",
    "    else:\n",
    "        EXECUTOR_CORES = CPUS_PER_NODE \n",
    "\n",
    "    try:\n",
    "        EXECUTOR_MEMORY = int(\n",
    "            MEM_PER_NODE / (CPUS_PER_NODE / EXECUTOR_CORES) * 0.5\n",
    "        )  # set executor memory in GB on each worker node\n",
    "    except ZeroDivisionError:\n",
    "        show_popup(f\"Please make sure you selected 3 nodes for the Spark Cluster, each with 24 GB of ram. You selected {MEM_PER_NODE} GB ram and {NODES} node(s)\")\n",
    "        \n",
    "    # Make sure there is a dir for spark logs\n",
    "    if not os.path.exists('spark_logs'):\n",
    "        os.mkdir('spark_logs')\n",
    "\n",
    "    conf = SparkConf().setAll(\n",
    "        [\n",
    "            (\"spark.app.name\", 'spark_assignment'), # Change to your liking \n",
    "            (\"spark.sql.caseSensitive\", False), # Optional: Make queries strings sensitive to captialization\n",
    "            (\"spark.master\", MASTER_HOST),\n",
    "            (\"spark.cores.max\", CLUSTER_CORES_MAX),\n",
    "            (\"spark.executor.cores\", EXECUTOR_CORES),\n",
    "            (\"spark.executor.memory\", str(EXECUTOR_MEMORY) + \"g\"),\n",
    "            (\"spark.eventLog.enabled\", True),\n",
    "            (\"spark.eventLog.dir\", \"spark_logs\"),\n",
    "            (\"spark.history.fs.logDirectory\", \"spark_logs\"),\n",
    "            (\"spark.deploy.mode\", \"cluster\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ## check executor memory, taking into accout 10% of memory overhead (minimum 384 MiB)\n",
    "    CHECK = (CLUSTER_CORES_MAX / EXECUTOR_CORES) * (\n",
    "        EXECUTOR_MEMORY + max(EXECUTOR_MEMORY * 0.10, 0.403)\n",
    "    )\n",
    "\n",
    "    assert (\n",
    "        int(CHECK) <= CLUSTER_MEMORY_MAX\n",
    "    ), \"Executor memory larger than cluster total memory!\"\n",
    "\n",
    "    # Stop previous session that was just for loading cluster params\n",
    "    spark.stop()\n",
    "\n",
    "    # Start new session with above config, that has better resource handling\n",
    "    spark = SparkSession.builder.config(conf=conf)\\\n",
    "                                .getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "    _EXECUTED_ = True\n",
    "    print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bbb4de-8b40-4364-b8d3-2cc488b16cbf",
   "metadata": {},
   "source": [
    "Click on the \"SparkMonitor\" tab at the top in Jupyter Lab to see the status of running code on the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1de3dec-d95c-44b9-a996-12e97cc34c2b",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "Here we specify where the yelp datasets are located on UCloud and read then using the spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fa96702-5902-4482-9cd2-77d6f5da0f75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:17:41.568023Z",
     "iopub.status.busy": "2024-10-08T17:17:41.567399Z",
     "iopub.status.idle": "2024-10-08T17:17:52.921683Z",
     "shell.execute_reply": "2024-10-08T17:17:52.912193Z",
     "shell.execute_reply.started": "2024-10-08T17:17:41.567985Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in the business and review files\n",
    "# This is the path to the shared datasets provided by adding an the dataset input folder\n",
    "# when submitting the spark cluster job.\n",
    "business = spark.read.json('file:////work/yelp/yelp_academic_dataset_business.json') # Use the file:/// prefix to indicate we want to read from the cluster's filesystem\n",
    "business = business.persist()\n",
    "# Persist 2 commonly used dataframes since they're used for later computations\n",
    "# https://sparkbyexamples.com/spark/spark-difference-between-cache-and-persist/\n",
    "\n",
    "users = spark.read.json(\"file:////work/yelp/yelp_academic_dataset_user.json\")\n",
    "\n",
    "reviews = spark.read.json('file:////work/yelp/yelp_academic_dataset_review.json')\n",
    "reviews = reviews.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a303b5b",
   "metadata": {},
   "source": [
    "## PySpark example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "235e5257-1a0e-4189-87fc-075ff2858c54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:15:59.976247Z",
     "iopub.status.busy": "2024-10-08T17:15:59.975661Z",
     "iopub.status.idle": "2024-10-08T17:15:59.981482Z",
     "shell.execute_reply": "2024-10-08T17:15:59.979925Z",
     "shell.execute_reply.started": "2024-10-08T17:15:59.976212Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show PySpark dataframes:\n",
    "#reviews.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afd9630e-1dd0-4abf-9952-bd7e252a8061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:16:02.127751Z",
     "iopub.status.busy": "2024-10-08T17:16:02.127138Z",
     "iopub.status.idle": "2024-10-08T17:16:02.131999Z",
     "shell.execute_reply": "2024-10-08T17:16:02.131122Z",
     "shell.execute_reply.started": "2024-10-08T17:16:02.127710Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#business.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e89f6184-410e-4a04-a4a1-7b080353dc1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T08:44:14.906267Z",
     "iopub.status.busy": "2024-10-04T08:44:14.905495Z",
     "iopub.status.idle": "2024-10-04T08:44:15.974016Z",
     "shell.execute_reply": "2024-10-04T08:44:15.972197Z",
     "shell.execute_reply.started": "2024-10-04T08:44:14.906206Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139885"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of rows with no sampling:\n",
    "reviews.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc31d1a2-3571-49cd-af5a-98d6d23027de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:16:07.106612Z",
     "iopub.status.busy": "2024-10-08T17:16:07.106239Z",
     "iopub.status.idle": "2024-10-08T17:16:07.125042Z",
     "shell.execute_reply": "2024-10-08T17:16:07.123945Z",
     "shell.execute_reply.started": "2024-10-08T17:16:07.106585Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OPTIONAL:\n",
    "# Reduce resource usage and make queries run faster\n",
    "# by only using a small sample of the dataframe\n",
    "# and overwriting previous variable \"df\".\n",
    "# Useful while developing, not so much to\n",
    "# provide final answers. Therefore: Remember to \n",
    "# to re-read the df when done developing code using\n",
    "# df = spark.read etc like above.\n",
    "reviews_frac = reviews.sample(withReplacement=False, fraction=1/50)\n",
    "\n",
    "# Get number of rows after sampling:\n",
    "#reviews_frac.count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20087cdb-d6f2-4aab-9fe2-bf3f072044db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:16:04.522202Z",
     "iopub.status.busy": "2024-10-08T17:16:04.521702Z",
     "iopub.status.idle": "2024-10-08T17:16:04.534390Z",
     "shell.execute_reply": "2024-10-08T17:16:04.533350Z",
     "shell.execute_reply.started": "2024-10-08T17:16:04.522166Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##sampling 1/50th of the total number\n",
    "#business = business.sample(withReplacement=False, fraction=1/50)\n",
    "#business.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d258fa6-1402-4c3a-a252-a9dbfd4a87d9",
   "metadata": {},
   "source": [
    "Example: Say we're only interested in reviews of good mexican restaurants in Arizona. You can delete this when you do your own thing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07983acb-15d8-45ea-9d12-3bc8759280b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:16:09.592814Z",
     "iopub.status.busy": "2024-10-08T17:16:09.592328Z",
     "iopub.status.idle": "2024-10-08T17:16:35.367969Z",
     "shell.execute_reply": "2024-10-08T17:16:35.367181Z",
     "shell.execute_reply.started": "2024-10-08T17:16:09.592786Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter to only Arizona businesses with \"Mexican\" as part of their categories\n",
    "az_mex = business.filter(business.state == \"AZ\")\\\n",
    "                .filter(business.categories.rlike(\"Mexican\"))\\\n",
    "                .select(\"business_id\", \"name\")\n",
    "\n",
    "# Join with the reviews\n",
    "az_mex_rs = reviews.join(az_mex, on=\"business_id\", how=\"inner\")\n",
    "\n",
    "# Filter to only 5 star reviews\n",
    "good_az_mex_rs = az_mex_rs.filter(az_mex_rs.stars == 5)\\\n",
    "                        .select(\"name\",\"text\")\n",
    "\n",
    "# Print the top 20 rows of the DataFrame\n",
    "#good_az_mex_rs.show()\n",
    "\n",
    "# Convert to pandas (local object) and save to local file system\n",
    "good_az_mex_rs.toPandas().to_csv(\"good_az_reviews.csv\", header=True, index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9d265d-cba4-4ade-851e-dad67771864b",
   "metadata": {},
   "source": [
    "See assignment PDF for task descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b394058",
   "metadata": {},
   "source": [
    "### Task 3.1.1: Total Number of Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee564c11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:16:35.440686Z",
     "iopub.status.busy": "2024-10-08T17:16:35.440423Z",
     "iopub.status.idle": "2024-10-08T17:16:43.121967Z",
     "shell.execute_reply": "2024-10-08T17:16:43.120840Z",
     "shell.execute_reply.started": "2024-10-08T17:16:35.440663Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|total_reviews|\n",
      "+-------------+\n",
      "|      6990280|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the total number of reviews for all businesses. The output should be in the form of a Spark Table/DataFrame with one value representing the count.\n",
    "# Count the total number of reviews\n",
    "total_reviews = reviews.count()\n",
    "\n",
    "# Create a DataFrame with one value representing the total number of reviews\n",
    "total_reviews_df = spark.createDataFrame([{\"total_reviews\": total_reviews}])\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "total_reviews_df.show()\n",
    "\n",
    "# Optionally, persist the result total_reviews_df.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a546fb",
   "metadata": {},
   "source": [
    "### Task 3.1.2: Businesses with 5 Stars and 500+ Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aca680c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:18:10.259122Z",
     "iopub.status.busy": "2024-10-08T17:18:10.258373Z",
     "iopub.status.idle": "2024-10-08T17:18:10.803648Z",
     "shell.execute_reply": "2024-10-08T17:18:10.802141Z",
     "shell.execute_reply.started": "2024-10-08T17:18:10.259069Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+-----+------------+\n",
      "|name                              |stars|review_count|\n",
      "+----------------------------------+-----+------------+\n",
      "|Blues City Deli                   |5.0  |991         |\n",
      "|Tumerico                          |5.0  |705         |\n",
      "|Free Tours By Foot                |5.0  |769         |\n",
      "|Yats                              |5.0  |623         |\n",
      "|SUGARED + BRONZED                 |5.0  |513         |\n",
      "|Nelson's Green Brier Distillery   |5.0  |545         |\n",
      "|Smiling With Hope Pizza           |5.0  |526         |\n",
      "|Carlillos Cocina                  |5.0  |799         |\n",
      "|Barracuda Deli Cafe St. Pete Beach|5.0  |521         |\n",
      "+----------------------------------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find all businesses that have received 5 stars and that have been reviewed by 500 ormore users. The output should be in the formof a DataFrame of (name, stars, review count).\n",
    "\n",
    "#filtering based on the criterias. utilizing review_count to look at the review coulmn\n",
    "filter_business = business.filter((business.stars == 5) & (business.review_count >= 500))\n",
    "\n",
    "#creating DF with relevant columns\n",
    "star_review_df = filter_business.select(\"name\", \"stars\", \"review_count\")\n",
    "\n",
    "star_review_df.show(truncate=False) # to avoid truncating long names i.e. shortening of long names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39e2a34",
   "metadata": {},
   "source": [
    "### Task 3.1.3: Influencers with 1000+ Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54a849fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:18:23.740429Z",
     "iopub.status.busy": "2024-10-08T17:18:23.740002Z",
     "iopub.status.idle": "2024-10-08T17:18:24.115603Z",
     "shell.execute_reply": "2024-10-08T17:18:24.114777Z",
     "shell.execute_reply.started": "2024-10-08T17:18:23.740406Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             user_id|\n",
      "+--------------------+\n",
      "|j14WgRoU_-2ZE1aw1...|\n",
      "|q_QQ5kBBwlCcbL1s4...|\n",
      "|MGPQVLsODMm9ZtYQW...|\n",
      "|NIhcRW6DWvk1JQhDh...|\n",
      "|QJI9OSEn6ujRCtrX0...|\n",
      "|AkBtT43dYcttxQ3qO...|\n",
      "|2l0O1EI1m0yWjFo2z...|\n",
      "|RgDVC3ZUBqpEe6Y1k...|\n",
      "|lquc6IF6uGIeRomDL...|\n",
      "|VHdY6oG2JPVNjihWh...|\n",
      "|om5ZiponkpRqUNa3p...|\n",
      "|K7thO1n-vZ9PFYiC7...|\n",
      "|UQFE3BT1rsIYrcDvu...|\n",
      "|jVYzrVblDFSuL3GHt...|\n",
      "|3zxy3LVBV3ttxoYbY...|\n",
      "|0G-QF457q_0Z_jKqh...|\n",
      "|ITa3vh5ERI90G_WP4...|\n",
      "|P5bUL3Engv-2z6kKo...|\n",
      "|ouODopBKF3AqfCkuQ...|\n",
      "|YMgZqBUAddmFErxLt...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find influencers who have written more than 1000 reviews. The output should be in the form of a Spark Table/DataFrame of user id. User gets queried with users\n",
    "users_sample = users.sample(withReplacement=False, fraction=1/50)\n",
    "#users_sample.show()\n",
    "\n",
    "reviews_user = users.filter(users.review_count >1000)\n",
    "\n",
    "reviews_user_df = reviews_user.select(\"user_id\")\n",
    "\n",
    "reviews_user_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a773c064",
   "metadata": {},
   "source": [
    "### Task 3.1.4: Businesses Reviewed by 5+ Influencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e383e06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:18:29.234586Z",
     "iopub.status.busy": "2024-10-08T17:18:29.234133Z",
     "iopub.status.idle": "2024-10-08T17:18:37.223071Z",
     "shell.execute_reply": "2024-10-08T17:18:37.221054Z",
     "shell.execute_reply.started": "2024-10-08T17:18:29.234561Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+\n",
      "|name                                 |\n",
      "+-------------------------------------+\n",
      "|Fleming’s Prime Steakhouse & Wine Bar|\n",
      "|Fat Dan's Deli                       |\n",
      "|BJ's Nevada Barbecue                 |\n",
      "|The Cheesecake Factory               |\n",
      "|Strangelove's                        |\n",
      "|Polite Society                       |\n",
      "|Peacemaker Lobster and Crab          |\n",
      "|Houlihan's                           |\n",
      "|Slice Pizzeria                       |\n",
      "|Blue Willow Restaurant & Gift Shop   |\n",
      "|Dim Sum Garden                       |\n",
      "|Pho Saigon                           |\n",
      "|Jeremiah's Italian Ice               |\n",
      "|Flying Fish Brewing Co               |\n",
      "|Regal Park Place & RPX               |\n",
      "|Barista Parlor                       |\n",
      "|Vanilla Bean Bakery                  |\n",
      "|Daredevil Brewing                    |\n",
      "|Antoine's Restaurant                 |\n",
      "|Repo Records                         |\n",
      "+-------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the businesses names that have been reviewed by more than 5 influencer users. You can use a view created from your answer to Q3.\n",
    "#users_sample.show()\n",
    "\n",
    "#need to join influencer users with the review DF\n",
    "influencer_reviews = reviews.join(reviews_user_df, on=\"user_id\")\n",
    "\n",
    "# Then grp by business_id, and count the number of infl reviews on each.\n",
    "business_influencer_count = influencer_reviews.groupBy(\"business_id\").count()\n",
    "\n",
    "#filtering\n",
    "business_with_influencers = business_influencer_count.filter(\"count > 5\")\n",
    "\n",
    "#join it with business DF to get the business names\n",
    "business_names_with_influencers = business_with_influencers.join(business, on=\"business_id\").select(\"name\")\n",
    "\n",
    "business_names_with_influencers.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8922a694",
   "metadata": {},
   "source": [
    "### Task 3.1.5: Ordered List of Users by Average Star Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64233be8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:18:40.363329Z",
     "iopub.status.busy": "2024-10-08T17:18:40.362580Z",
     "iopub.status.idle": "2024-10-08T17:18:43.042204Z",
     "shell.execute_reply": "2024-10-08T17:18:43.041339Z",
     "shell.execute_reply.started": "2024-10-08T17:18:40.363277Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|   name|average_stars|\n",
      "+-------+-------------+\n",
      "|Brandon|          5.0|\n",
      "|   Dave|          5.0|\n",
      "|William|          5.0|\n",
      "|Michael|          5.0|\n",
      "|   Kari|          5.0|\n",
      "|    Meg|          5.0|\n",
      "|  Glenn|          5.0|\n",
      "|Allison|          5.0|\n",
      "|   Kyla|          5.0|\n",
      "|  Emily|          5.0|\n",
      "|Pierric|          5.0|\n",
      "|Nichole|          5.0|\n",
      "| Pierce|          5.0|\n",
      "|  Peter|          5.0|\n",
      "|Cameron|          5.0|\n",
      "|  Scott|          5.0|\n",
      "|  Craig|          5.0|\n",
      "|Melissa|          5.0|\n",
      "|   Alan|          5.0|\n",
      "| Audrey|          5.0|\n",
      "+-------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Find an ordered list of users based on the average star counts they have given in all their reviews.\n",
    "\n",
    "# Users contain a column called average_stars\n",
    "# So we can just use orderBy, where ascending then = False\n",
    "ordered_users_by_avg_stars = users.orderBy(\"average_stars\", ascending=False)\n",
    "\n",
    "presentable_df = ordered_users_by_avg_stars.select(\"name\" , \"average_stars\")\n",
    "\n",
    "#ordered_users_by_avg_stars.show()\n",
    "presentable_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa6bec7",
   "metadata": {},
   "source": [
    "### Task 3.2.1: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37eadc69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:18:53.270369Z",
     "iopub.status.busy": "2024-10-08T17:18:53.269834Z",
     "iopub.status.idle": "2024-10-08T17:19:13.631187Z",
     "shell.execute_reply": "2024-10-08T17:19:13.630332Z",
     "shell.execute_reply.started": "2024-10-08T17:18:53.270337Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+\n",
      "|contains_authentic|contains_legitimate|\n",
      "+------------------+-------------------+\n",
      "|            124634|              23187|\n",
      "+------------------+-------------------+\n",
      "\n",
      "+------------------+-------------------+\n",
      "|        %authentic|        %legitimate|\n",
      "+------------------+-------------------+\n",
      "|1.7829614836601682|0.33170345107778226|\n",
      "+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look in the data for the use of \"authenticity language\", as defined in the Eater New York article. These queries should include (but not be limited to) the following questions:\n",
    "# • What is the percentage of reviews that contain a variant of the word \"authentic\"? \n",
    "\n",
    "#reviews_sample = reviews.sample(withReplacement=False, fraction=1/50)\n",
    "#reviews_sample.show()\n",
    "\n",
    "#can be done using col, lower from sql.function without converting into rdd\n",
    "from pyspark.sql.functions import lower, col\n",
    "\n",
    "reviews_count = reviews.count()\n",
    "\n",
    "#lower(col()) is to make sure we can cross reference the text. .contains() works like maps or sets in java\n",
    "reviews_filter_authentic = reviews.filter(lower(col(\"text\")).contains(\"authentic\"))\n",
    "\n",
    "reviews_filter_likelegitimate = reviews.filter(lower(col(\"text\")).contains(\"legitimate\") | lower(col(\"text\")).contains(\"legit\"))\n",
    "\n",
    "#counting the amount of reviews containing our filter words\n",
    "authentic_reviews_count = reviews_filter_authentic.count()\n",
    "\n",
    "legitimate_reviews_count = reviews_filter_likelegitimate.count()\n",
    "\n",
    "overall_filterwords_df = spark.createDataFrame([{\"contains_authentic\": authentic_reviews_count, \"contains_legitimate\": legitimate_reviews_count}])\n",
    "\n",
    "overall_filterwords_df.show()\n",
    "\n",
    "percentage_with_authentic = (authentic_reviews_count/reviews_count)*100\n",
    "percentage_with_legitimate = (legitimate_reviews_count/reviews_count)*100\n",
    "\n",
    "percentage_with_filterwordsdf = spark.createDataFrame([{\"%authentic\": percentage_with_authentic, \"%legitimate\": percentage_with_legitimate}])\n",
    "\n",
    "percentage_with_filterwordsdf.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94b404ea-d934-4098-8bf5-635e4f9de2da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:19:19.615558Z",
     "iopub.status.busy": "2024-10-08T17:19:19.615101Z",
     "iopub.status.idle": "2024-10-08T17:19:36.916136Z",
     "shell.execute_reply": "2024-10-08T17:19:36.915220Z",
     "shell.execute_reply.started": "2024-10-08T17:19:19.615531Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146428"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding the filtered words toegether in a table we can take from.\n",
    "from pyspark.sql.functions import lower, col\n",
    "reviews_with_filterwords = reviews.filter(lower(col(\"text\")).contains(\"legitimate\")\\\n",
    "                                                 | lower(col(\"text\")).contains(\"legit\")\\\n",
    "                                                 | lower(col(\"text\")).contains(\"authentic\"))\n",
    "reviews_with_filterwords.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d890ad-9ebe-4f91-9225-a99b89caa6d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T15:17:51.968404Z",
     "iopub.status.busy": "2024-10-06T15:17:51.967593Z",
     "iopub.status.idle": "2024-10-06T15:17:51.995138Z",
     "shell.execute_reply": "2024-10-06T15:17:51.993580Z",
     "shell.execute_reply.started": "2024-10-06T15:17:51.968348Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Looking for country and cuisines from the 'categories' column\n",
    "unique_categories = business.select(\"categories\").distinct()\n",
    "\n",
    "# Show the unique categories\n",
    "#unique_categories.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff3c0c6e-511f-4e24-a2c5-9ea735eb1eba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:20:05.243377Z",
     "iopub.status.busy": "2024-10-08T17:20:05.242944Z",
     "iopub.status.idle": "2024-10-08T17:20:22.947481Z",
     "shell.execute_reply": "2024-10-08T17:20:22.946451Z",
     "shell.execute_reply.started": "2024-10-08T17:20:05.243336Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "|      cuisine|authentic_reviews|\n",
      "+-------------+-----------------+\n",
      "|      Mexican|            31739|\n",
      "|         Thai|             5887|\n",
      "|       Indian|             5366|\n",
      "|      Chinese|            13432|\n",
      "|      African|              258|\n",
      "|    Taiwanese|              207|\n",
      "|        Irish|              587|\n",
      "|     Japanese|             4696|\n",
      "|   Vietnamese|             4167|\n",
      "|      Italian|            11337|\n",
      "|    Caribbean|             1627|\n",
      "|       Korean|             3090|\n",
      "|       French|             1073|\n",
      "|Mediterranean|             5145|\n",
      "|     American|            20720|\n",
      "+-------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many reviews contain the string \"legitimate\" grouped by type of cuisine?\n",
    "from pyspark.sql import functions as func\n",
    "\n",
    "target_businesses = business.withColumn(\"cuisine\", func.when(func.col(\"categories\").rlike(\"(?i)Chinese\"),\"Chinese\")\\\n",
    "                                        .when(func.col(\"categories\").rlike(\"(?i)American\"),\"American\")\n",
    "                                        .when(func.col(\"categories\").rlike(\"(?i)Korean\"),\"Korean\")\n",
    "                                        .when(func.col(\"categories\").rlike(\"(?i)Japanese\"),\"Japanese\")\n",
    "                                        .when(func.col(\"categories\").rlike(\"(?i)Thai\"),\"Thai\")\n",
    "                                        .when(func.col(\"categories\").rlike(\"(?i)Mexican\"),\"Mexican\")\n",
    "                                        .when(func.col(\"categories\").rlike(\"(?i)Mediterranean\"),\"Mediterranean\")\n",
    "                                        .when(func.col(\"categories\").rlike(\"(?i)Irish\"),\"Irish\")\n",
    "                                        .when(func.col(\"categories\").rlike(\"(?i)Italian\"),\"Italian\")\n",
    "                                        .when(func.col(\"categories\").rlike(\"(?i)French\"),\"French\")\n",
    "                                        .when(func.col(\"categories\").rlike(\"(?i)Taiwanese\"),\"Taiwanese\")\n",
    "                                        .when(func.col(\"categories\").rlike(\"(?i)Caribbean\"),\"Caribbean\")\n",
    "                                        .when(func.col(\"categories\").rlike(\"(?i)Indian\"),\"Indian\")\n",
    "                                        .when(func.col(\"categories\").rlike(\"(?i)Vietnamese\"),\"Vietnamese\")\n",
    "                                        .when(func.col(\"categories\").rlike(\"(?i)African\"),\"African\"))\n",
    "#consider potential null values\n",
    "target_businesses = target_businesses.filter(~target_businesses.cuisine.rlike(\"null\"))\n",
    "\n",
    "#Joining target business with the reviews w filtered words\n",
    "totalauthentic_review_with_cuisine = reviews_with_filterwords.join(target_businesses, on=\"business_id\")\n",
    "\n",
    "#then we group it by cuisine\n",
    "review_by_cuisine = totalauthentic_review_with_cuisine.groupBy(\"cuisine\").count().withColumnRenamed(\"count\", \"authentic_reviews\")\n",
    "\n",
    "review_by_cuisine.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19bd1c2d-c1be-4c70-8bfc-56f2d0184ffa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:20:28.226861Z",
     "iopub.status.busy": "2024-10-08T17:20:28.226386Z",
     "iopub.status.idle": "2024-10-08T17:20:47.812779Z",
     "shell.execute_reply": "2024-10-08T17:20:47.812038Z",
     "shell.execute_reply.started": "2024-10-08T17:20:28.226836Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+-------------+------------------+\n",
      "|      cuisine|authentic_reviews|total_reviews|%authentic_reviews|\n",
      "+-------------+-----------------+-------------+------------------+\n",
      "|     American|            20720|      1718517|1.2056907205456797|\n",
      "|       French|             1073|        39742| 2.699914448190831|\n",
      "|     Japanese|             4696|       165915|2.8303649459060365|\n",
      "|      Italian|            11337|       338519| 3.348999613020244|\n",
      "|        Irish|              587|        16750| 3.504477611940299|\n",
      "|Mediterranean|             5145|        99829| 5.153813020264653|\n",
      "|      Chinese|            13432|       224265| 5.989342964796112|\n",
      "|       Korean|             3090|        44993| 6.867734980997044|\n",
      "|         Thai|             5887|        82347| 7.149015750421994|\n",
      "|   Vietnamese|             4167|        57331| 7.268319059496607|\n",
      "|      African|              258|         3483|7.4074074074074066|\n",
      "|       Indian|             5366|        70532| 7.607894289116997|\n",
      "|    Taiwanese|              207|         2666| 7.764441110277569|\n",
      "|    Caribbean|             1627|        17912| 9.083296114336758|\n",
      "|      Mexican|            31739|       344238| 9.220074483351635|\n",
      "+-------------+-----------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How big of a percentage of the total reviews are \"authentic\" reviews?\n",
    "\n",
    "# Start by counting the total amount reviews per targeted cuisines\n",
    "table_incl_treviews = reviews.join(target_businesses, on=\"business_id\")\n",
    "\n",
    "totalreviews_by_cuisine = table_incl_treviews.groupBy(\"cuisine\").count().withColumnRenamed(\"count\", \"total_reviews\")\n",
    "\n",
    "#combine totalreviews with the previous review_by_cuisine table.\n",
    "reviews_incl_percent = review_by_cuisine.join(totalreviews_by_cuisine, on=\"cuisine\")\n",
    "\n",
    "# Calculate the % directly in a coulmn, by using the other coulmns and overwride the old table\n",
    "# remaning the count column of the % ws_count\")/F.col(\"totalReviewsCuisines\")*100)\n",
    "\n",
    "reviews_incl_percent = reviews_incl_percent.withColumn(\"%authentic_reviews\", func.col(\"authentic_reviews\")/func.col(\"total_reviews\")*100)\n",
    "\n",
    "reviews_incl_percent.orderBy(\"%authentic_reviews\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0579b692-cc41-4a73-899e-cc87805f0c79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T16:37:43.841249Z",
     "iopub.status.busy": "2024-10-06T16:37:43.840254Z",
     "iopub.status.idle": "2024-10-06T16:39:00.890825Z",
     "shell.execute_reply": "2024-10-06T16:39:00.889298Z",
     "shell.execute_reply.started": "2024-10-06T16:37:43.841190Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+------------------+\n",
      "|total_amount_north|amount_north|        %authentic|\n",
      "+------------------+------------+------------------+\n",
      "|           2318184|       51555|2.2239390833514507|\n",
      "+------------------+------------+------------------+\n",
      "\n",
      "+------------------+------------+------------------+\n",
      "|total_amount_south|amount_south|        %authentic|\n",
      "+------------------+------------+------------------+\n",
      "|           4672096|       94873|2.0306303637596486|\n",
      "+------------------+------------+------------------+\n",
      "\n",
      "+-----------------+-----------+-----------------+\n",
      "|total_amount_east|amount_east|       %authentic|\n",
      "+-----------------+-----------+-----------------+\n",
      "|          5512078|     118118|2.142894204327297|\n",
      "+-----------------+-----------+-----------------+\n",
      "\n",
      "+-----------------+-----------+------------------+\n",
      "|total_amount_west|amount_west|        %authentic|\n",
      "+-----------------+-----------+------------------+\n",
      "|          1478202|      28310|1.9151645039040672|\n",
      "+-----------------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Is there a difference in the amount of authenticity language used in the different areas? (e.g., by state, north/south, urban/rural)\n",
    "#business.show()\n",
    "\n",
    "USA_mid_latitude = 39.8283\n",
    "USA_mid_longitude = -98.5795\n",
    "\n",
    "#USA_south = business.filter(\"laitutde\" < USA_mid_latitude) #need to import col here to make it work\n",
    "\n",
    "# Filter using a string-based condition, referencing the latitude column directly\n",
    "USA_south = business.filter(f\"latitude < {USA_mid_latitude}\")\n",
    "USA_north = business.filter(f\"latitude > {USA_mid_latitude}\")\n",
    "\n",
    "USA_east = business.filter(f\"longitude > {USA_mid_longitude}\")\n",
    "USA_west = business.filter(f\"longitude < {USA_mid_longitude}\")\n",
    "\n",
    "#total reviews\n",
    "total_reviews_north = reviews.join(USA_north, \"business_id\").count()\n",
    "total_reviews_south = reviews.join(USA_south, \"business_id\").count()\n",
    "\n",
    "total_reviews_east = reviews.join(USA_east, \"business_id\").count()\n",
    "total_reviews_west= reviews.join(USA_west, \"business_id\").count()\n",
    "\n",
    "#USA_south.show()\n",
    "#USA_north.show()\n",
    "\n",
    "\n",
    "#reviews_filter = reviews.filter(lower(col(\"text\")).contains(\"authentic\"))\n",
    "\n",
    "#reviews_with_filterwords\n",
    "\n",
    "# Join reviews with south and north businesses based on 'business_id'\n",
    "authentic_reviews_north = reviews_with_filterwords.join(USA_north, \"business_id\")\n",
    "authentic_reviews_south = reviews_with_filterwords.join(USA_south, \"business_id\")\n",
    "\n",
    "authentic_reviews_east = reviews_with_filterwords.join(USA_east, \"business_id\")\n",
    "authentic_reviews_west = reviews_with_filterwords.join(USA_west, \"business_id\")\n",
    "\n",
    "# Count the number of 'authentic' reviews in the north and south\n",
    "reviews_WN_authentic_count = authentic_reviews_north.count()\n",
    "reviews_WS_authentic_count = authentic_reviews_south.count()\n",
    "\n",
    "reviews_WE_authentic_count = authentic_reviews_east.count()\n",
    "reviews_WW_authentic_count = authentic_reviews_west.count()\n",
    "\n",
    "# count % usage in order to see the difference between east, west, north and south\n",
    "percentage_with_filterwords_north = (reviews_WN_authentic_count/total_reviews_north)*100\n",
    "percentage_with_filterwords_south = (reviews_WS_authentic_count/total_reviews_south)*100\n",
    "percentage_with_filterwords_east = (reviews_WE_authentic_count/total_reviews_east)*100\n",
    "percentage_with_filterwords_west = (reviews_WW_authentic_count/total_reviews_west)*100\n",
    "\n",
    "# Make DataFrames. Keep in mind each {} indicates a dictionary\n",
    "USA_north_df = spark.createDataFrame([{\"amount_north\": reviews_WN_authentic_count,\n",
    "                                      \"total_amount_north\": total_reviews_north,\n",
    "                                      \"%authentic\": percentage_with_filterwords_north\n",
    "                                      }])\n",
    "\n",
    "\n",
    "USA_south_df = spark.createDataFrame([{\"amount_south\": reviews_WS_authentic_count,\n",
    "                                      \"total_amount_south\": total_reviews_south,\n",
    "                                      \"%authentic\": percentage_with_filterwords_south\n",
    "                                      }])\n",
    "\n",
    "USA_east_df = spark.createDataFrame([{\"amount_east\": reviews_WE_authentic_count,\n",
    "                                      \"total_amount_east\": total_reviews_east,\n",
    "                                      \"%authentic\": percentage_with_filterwords_east\n",
    "                                      }])\n",
    "\n",
    "USA_west_df = spark.createDataFrame([{\"amount_west\": reviews_WW_authentic_count,\n",
    "                                      \"total_amount_west\": total_reviews_west,\n",
    "                                      \"%authentic\": percentage_with_filterwords_west\n",
    "                                      }])\n",
    "\n",
    "USA_north_df.select(\"total_amount_north\", \"amount_north\", \"%authentic\").show()\n",
    "USA_south_df.select(\"total_amount_south\", \"amount_south\", \"%authentic\").show()\n",
    "USA_east_df.select(\"total_amount_east\", \"amount_east\", \"%authentic\").show()\n",
    "USA_west_df.select(\"total_amount_west\", \"amount_west\", \"%authentic\").show()\n",
    "\n",
    "\n",
    "# Note: As part of answering this question, you could compute the full cube or rollup combining the location of the business and whether the review contains authenticity language,\n",
    "# and use this to aggregate their counts per state and city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28249641-ae35-48e8-8852-c4c22e725142",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:21:03.297239Z",
     "iopub.status.busy": "2024-10-08T17:21:03.296732Z",
     "iopub.status.idle": "2024-10-08T17:21:03.348127Z",
     "shell.execute_reply": "2024-10-08T17:21:03.347360Z",
     "shell.execute_reply.started": "2024-10-08T17:21:03.297199Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's try to create quadrants rather than halving USA based on north/south and east/west\n",
    "# For this purpose I'll do nortEast, northWest, southEast and southWest\n",
    "USA_mid_latitude = 39.8283\n",
    "USA_mid_longitude = -98.5795\n",
    "\n",
    "# including quadrants in the business filtering\n",
    "business_with_geo = business.withColumn(\"geo_area\",\\\n",
    "                                        func.when((func.col(\"latitude\") > USA_mid_latitude) & (func.col(\"longitude\") > USA_mid_longitude), \"NorthEast\")\n",
    "                                        .when((func.col(\"latitude\") > USA_mid_latitude) & (func.col(\"longitude\") < USA_mid_longitude), \"NorthWest\")\n",
    "                                        .when((func.col(\"latitude\") < USA_mid_latitude) & (func.col(\"longitude\") > USA_mid_longitude), \"SouthEast\")\n",
    "                                        .when((func.col(\"latitude\") < USA_mid_latitude) & (func.col(\"longitude\") < USA_mid_longitude), \"SouthWest\")\n",
    "                                       )\n",
    "#deal with null values\n",
    "business_with_geo = business_with_geo.filter(~business_with_geo.geo_area.rlike(\"null\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40bd3ed3-fc55-4ce6-b0d4-81fb51f749f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:48:28.128208Z",
     "iopub.status.busy": "2024-10-08T17:48:28.126988Z",
     "iopub.status.idle": "2024-10-08T17:48:45.718031Z",
     "shell.execute_reply": "2024-10-08T17:48:45.692055Z",
     "shell.execute_reply.started": "2024-10-08T17:48:28.128131Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+------------------+------------------+\n",
      "| geo_area|total_per_area|authentic_per_area|%_authentic_review|\n",
      "+---------+--------------+------------------+------------------+\n",
      "|SouthEast|       3460933|             72058| 2.082039727437659|\n",
      "|SouthWest|       1211163|             22815|1.8837266329965494|\n",
      "|NorthWest|        267039|              5495| 2.057751863959946|\n",
      "|NorthEast|       2051145|             46060|2.2455750324818577|\n",
      "+---------+--------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#combining the idea of geo area with the total, authentic and %reviews\n",
    "business_geo_authentic = business_with_geo.join(reviews_with_filterwords, on=\"business_id\")\n",
    "\n",
    "# let's group by geo area\n",
    "business_geo_authentic_sorted = business_geo_authentic.groupBy(\"geo_area\").count().withColumnRenamed(\"count\", \"authentic_per_area\")\n",
    "\n",
    "# query total review by quadrant\n",
    "business_geo_total = business_with_geo.join(reviews, on=\"business_id\")\n",
    "\n",
    "#Sort by area\n",
    "business_geo_total_sorted = business_geo_total.groupBy(\"geo_area\").count().withColumnRenamed(\"count\", \"total_per_area\")\n",
    "\n",
    "#combine the tables and craft the percentage column\n",
    "business_geo_percent = business_geo_total_sorted.join(business_geo_authentic_sorted, on=\"geo_area\").withColumn(\"%_authentic_review\",\\\n",
    "                                                                                                               (func.col(\"authentic_per_area\")/\n",
    "                                                                                                               func.col(\"total_per_area\"))*100)\n",
    "business_geo_percent.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38ab6ec3-f734-425f-9cc2-c64f78c611d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:21:50.534143Z",
     "iopub.status.busy": "2024-10-08T17:21:50.533706Z",
     "iopub.status.idle": "2024-10-08T17:22:08.240072Z",
     "shell.execute_reply": "2024-10-08T17:22:08.239253Z",
     "shell.execute_reply.started": "2024-10-08T17:21:50.534116Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------------+\n",
      "| geo_area|      cuisine|authentic_reviews|\n",
      "+---------+-------------+-----------------+\n",
      "|SouthWest|       Indian|              709|\n",
      "|SouthEast|       French|              557|\n",
      "|SouthEast|      African|              119|\n",
      "|SouthWest|         Thai|              752|\n",
      "|NorthEast|     Japanese|             1544|\n",
      "|SouthEast|      Chinese|             4610|\n",
      "|NorthEast|       Indian|             2208|\n",
      "|SouthEast|      Italian|             5383|\n",
      "|SouthWest|    Taiwanese|               27|\n",
      "|NorthWest|       Korean|              208|\n",
      "|SouthEast|     American|            11631|\n",
      "|NorthWest|       French|               71|\n",
      "|NorthWest|      Italian|              482|\n",
      "|SouthEast|    Caribbean|             1003|\n",
      "|NorthEast|     American|             5957|\n",
      "|SouthEast|   Vietnamese|             2152|\n",
      "|NorthWest|Mediterranean|              159|\n",
      "|SouthEast|         Thai|             3106|\n",
      "|SouthEast|      Mexican|            14658|\n",
      "|NorthWest|      Mexican|             1017|\n",
      "|SouthWest|      Italian|             1488|\n",
      "|SouthWest|   Vietnamese|              492|\n",
      "|SouthEast|Mediterranean|             2363|\n",
      "|NorthWest|       Indian|              234|\n",
      "|SouthEast|       Korean|             1237|\n",
      "|SouthWest|Mediterranean|              605|\n",
      "|NorthEast|    Caribbean|              544|\n",
      "|NorthEast|   Vietnamese|             1327|\n",
      "|NorthEast|      Chinese|             5714|\n",
      "|SouthEast|     Japanese|             1906|\n",
      "|NorthWest|      Chinese|              532|\n",
      "|NorthWest|         Thai|              297|\n",
      "|NorthEast|        Irish|              166|\n",
      "|NorthEast|      Italian|             3984|\n",
      "|SouthWest|       Korean|              475|\n",
      "|NorthEast|Mediterranean|             2018|\n",
      "|NorthWest|     Japanese|              277|\n",
      "|NorthEast|       Korean|             1170|\n",
      "|SouthWest|      Chinese|             2576|\n",
      "|SouthWest|     American|             2627|\n",
      "|SouthWest|     Japanese|              969|\n",
      "|SouthEast|       Indian|             2215|\n",
      "|NorthEast|      African|               73|\n",
      "|NorthWest|   Vietnamese|              196|\n",
      "|NorthEast|         Thai|             1732|\n",
      "|SouthWest|      Mexican|             7010|\n",
      "|SouthWest|       French|              138|\n",
      "|NorthEast|      Mexican|             9054|\n",
      "|NorthWest|     American|              505|\n",
      "|SouthWest|      African|               37|\n",
      "|NorthWest|    Taiwanese|               17|\n",
      "|SouthEast|        Irish|              359|\n",
      "|SouthWest|    Caribbean|               65|\n",
      "|NorthEast|       French|              307|\n",
      "|SouthWest|        Irish|               50|\n",
      "|NorthEast|    Taiwanese|               62|\n",
      "|NorthWest|    Caribbean|               15|\n",
      "|NorthWest|      African|               29|\n",
      "|SouthEast|    Taiwanese|              101|\n",
      "|NorthWest|        Irish|               12|\n",
      "+---------+-------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's try to include the cuisines in the table to look for potential biases\n",
    "#reviews_incl_percent = reviews_incl_percent.withColumn(\"%authentic_reviews\", func.col(\"authentic_reviews\")/func.col(\"total_reviews\")*100)\n",
    "\n",
    "#totalreviews_by_cuisine = table_incl_treviews.groupBy(\"cuisine\").count().withColumnRenamed(\"count\", \"total_reviews\")\n",
    "\n",
    "totalauthentic_with_geo = totalauthentic_review_with_cuisine.join(business_with_geo.select(\"business_id\", \"geo_area\"), on=\"business_id\")\n",
    "\n",
    "#filtered_review_w_geo = totalauthentic_with_geo.join(business_geo_authentic, on=\"business_id\")\n",
    "\n",
    "#business_id, cuisine, geo_area|\n",
    "\n",
    "#business_geo_total \n",
    "\n",
    "geo_cuisine_reviews = totalauthentic_with_geo.groupBy(\"geo_area\", \"cuisine\").count().withColumnRenamed(\"count\", \"authentic_reviews\")\n",
    "\n",
    "geo_cuisine_reviews.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8517b579",
   "metadata": {},
   "source": [
    "### Task 3.2.2: Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10fc0e55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:58:11.144655Z",
     "iopub.status.busy": "2024-10-08T17:58:11.143643Z",
     "iopub.status.idle": "2024-10-08T17:58:44.069744Z",
     "shell.execute_reply": "2024-10-08T17:58:44.068015Z",
     "shell.execute_reply.started": "2024-10-08T17:58:11.144577Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+---------------------+------------------+\n",
      "|      cuisine|authentic_reviews|amount_negative_words| %negative_reviews|\n",
      "+-------------+-----------------+---------------------+------------------+\n",
      "|    Caribbean|             1627|                   87| 5.347264904732637|\n",
      "|       Indian|             5366|                  379| 7.062989191203877|\n",
      "|        Irish|              587|                   46| 7.836456558773425|\n",
      "|Mediterranean|             5145|                  413| 8.027210884353742|\n",
      "|      African|              258|                   21|  8.13953488372093|\n",
      "|      Italian|            11337|                  927| 8.176766340301667|\n",
      "|         Thai|             5887|                  490| 8.323424494649228|\n",
      "|       Korean|             3090|                  289| 9.352750809061488|\n",
      "|     American|            20720|                 2082| 10.04826254826255|\n",
      "|    Taiwanese|              207|                   21|10.144927536231885|\n",
      "|     Japanese|             4696|                  479|10.200170357751277|\n",
      "|       French|             1073|                  115|10.717614165890028|\n",
      "|      Mexican|            31739|                 3470|10.932921642143736|\n",
      "|   Vietnamese|             4167|                  491|11.783057355411566|\n",
      "|      Chinese|            13432|                 1809|13.467837998808815|\n",
      "+-------------+-----------------+---------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write your code here...\n",
    "\n",
    "# Let's look into the hypothesis good reviews vs bad reviews\n",
    "# We go back and grab our target business with cuisines, which has our total amount of authentic reviews\n",
    "negative_authentic_reviews = totalauthentic_review_with_cuisine.filter(\n",
    "    func.col(\"text\").rlike(\"(?i)dirt(y)|kitsch(y)|tacky|corny|dodgy|oily|greasy|cheap|simple|rude\")\n",
    ")\n",
    "\n",
    "# now that we've filtered we can groupby and rename the column ot make more sense for displaying.\n",
    "negative_authentic_reviews_filtered = negative_authentic_reviews.groupBy(\"cuisine\").count()\n",
    "negative_authentic_reviews_filtered = negative_authentic_reviews_filtered.withColumnRenamed(\"count\", \"amount_negative_words\")\n",
    "\n",
    "#rejoin our filtered version with table containing the overall authentic review count. Here we can use the grouped one to get authentic count\n",
    "negative_authentic_reviews_stats = negative_authentic_reviews_filtered.join(review_by_cuisine, \"cuisine\")\n",
    "\n",
    "#Then we add the percentage column\n",
    "negative_authentic_reviews_stats = negative_authentic_reviews_stats.withColumn(\"%negative_reviews\",\\\n",
    "                                                                               (func.col(\"amount_negative_words\")\\\n",
    "                                                                                /func.col(\"authentic_reviews\")*100))\n",
    "\n",
    "negative_authentic_reviews_stats.select(\"cuisine\", \"authentic_reviews\",\\\n",
    "                                        \"amount_negative_words\", \"%negative_reviews\").orderBy(\"%negative_reviews\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b13524f-32bc-4c12-af23-0900286cc428",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T17:27:21.452914Z",
     "iopub.status.busy": "2024-10-08T17:27:21.452350Z",
     "iopub.status.idle": "2024-10-08T17:27:54.510370Z",
     "shell.execute_reply": "2024-10-08T17:27:54.509241Z",
     "shell.execute_reply.started": "2024-10-08T17:27:21.452876Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+---------------------+------------------+\n",
      "|      cuisine|authentic_reviews|amount_positive_words| %positive_reviews|\n",
      "+-------------+-----------------+---------------------+------------------+\n",
      "|      Mexican|            31739|                  687|2.1645294432716846|\n",
      "|       Korean|             3090|                   68|2.2006472491909386|\n",
      "|   Vietnamese|             4167|                   97| 2.327813774898008|\n",
      "|      Chinese|            13432|                  326|2.4270399047051816|\n",
      "|        Irish|              587|                   16|  2.72572402044293|\n",
      "|      African|              258|                    8|  3.10077519379845|\n",
      "|    Taiwanese|              207|                    7|3.3816425120772946|\n",
      "|    Caribbean|             1627|                   57| 3.503380454824831|\n",
      "|       Indian|             5366|                  194|3.6153559448378685|\n",
      "|     Japanese|             4696|                  191| 4.067291311754684|\n",
      "|     American|            20720|                  901| 4.348455598455598|\n",
      "|Mediterranean|             5145|                  244| 4.742468415937804|\n",
      "|      Italian|            11337|                  553| 4.877833642056982|\n",
      "|         Thai|             5887|                  300| 5.095974180397486|\n",
      "|       French|             1073|                   92| 8.574091332712023|\n",
      "+-------------+-----------------+---------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We go back and grab our target business with cuisines, which has our total amount of authentic reviews\n",
    "positive_authentic_reviews = totalauthentic_review_with_cuisine.filter(\n",
    "    func.col(\"text\").rlike(\"(?i)elegant|elegance|tasteful|cultivated|refined|beautiful|innovative\")\n",
    ")\n",
    "\n",
    "# now that we've filtered we can groupby and rename the column ot make more sense for displaying.\n",
    "positive_authentic_reviews_filtered = positive_authentic_reviews.groupBy(\"cuisine\").count()\n",
    "positive_authentic_reviews_filtered = positive_authentic_reviews_filtered.withColumnRenamed(\"count\", \"amount_positive_words\")\n",
    "\n",
    "#rejoin our filtered version with table containing the overall authentic review count. Here we can use the grouped one to get authentic count\n",
    "positive_authentic_reviews_stats = positive_authentic_reviews_filtered.join(review_by_cuisine, \"cuisine\")\n",
    "\n",
    "#Then we add the percentage column\n",
    "positive_authentic_reviews_stats = positive_authentic_reviews_stats.withColumn(\"%positive_reviews\",\\\n",
    "                                                                               (func.col(\"amount_positive_words\")\\\n",
    "                                                                                /func.col(\"authentic_reviews\")*100))\n",
    "\n",
    "positive_authentic_reviews_stats.select(\"cuisine\", \"authentic_reviews\",\\\n",
    "                                        \"amount_positive_words\", \"%positive_reviews\").orderBy(\"%positive_reviews\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf16b5cc-93a8-428c-b94a-664f5b477b49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T18:05:20.815553Z",
     "iopub.status.busy": "2024-10-08T18:05:20.815117Z",
     "iopub.status.idle": "2024-10-08T18:05:54.714361Z",
     "shell.execute_reply": "2024-10-08T18:05:54.712876Z",
     "shell.execute_reply.started": "2024-10-08T18:05:20.815528Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+----------------------------------+-----------------+\n",
      "| geo_area|authentic_per_area|amount_reviews_with_negative_words|%negative_reviews|\n",
      "+---------+------------------+----------------------------------+-----------------+\n",
      "|SouthEast|             72058|                              4853| 6.73485247994671|\n",
      "|NorthWest|              5495|                               411|7.479526842584168|\n",
      "|SouthWest|             22815|                              1846|8.091168091168091|\n",
      "|NorthEast|             46060|                              4009|8.703864524533216|\n",
      "+---------+------------------+----------------------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's try to look at hte positive reviews based on our geographical data.\n",
    "#negative_authentic_reviews.show(10)\n",
    "negative_authentic_reviews_for_geo = negative_authentic_reviews.join(business_with_geo, on=\"business_id\")\n",
    "\n",
    "# We then group by geo_area column and count them.\n",
    "negative_authentic_reviews_grouped = negative_authentic_reviews_for_geo.groupBy(\"geo_area\").count()\n",
    "negative_authentic_reviews_grouped = negative_authentic_reviews_grouped.withColumnRenamed\\\n",
    "(\"count\",\"amount_reviews_with_negative_words\")\n",
    "\n",
    "#negative_authentic_reviews_grouped.show(10)\n",
    "\n",
    "#Join with the table over geographical locations\n",
    "overall_geo_area_and_negative_words = negative_authentic_reviews_grouped.join(business_geo_percent, on=\"geo_area\")\n",
    "\n",
    "overall_geo_area_and_negative_words = overall_geo_area_and_negative_words.withColumn(\"%negative_reviews\",\\\n",
    "                                                                         (F.col(\"amount_reviews_with_negative_words\")\\\n",
    "                                                                         /F.col(\"authentic_per_area\"))*100)\n",
    "\n",
    "overall_geo_area_and_negative_words.select(\"geo_area\",\"authentic_per_area\",\"amount_reviews_with_negative_words\",\"%negative_reviews\").orderBy(\"%negative_reviews\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8065861-6b61-4702-a83c-76dae6b386a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T18:08:06.507551Z",
     "iopub.status.busy": "2024-10-08T18:08:06.507182Z",
     "iopub.status.idle": "2024-10-08T18:08:41.620246Z",
     "shell.execute_reply": "2024-10-08T18:08:41.619404Z",
     "shell.execute_reply.started": "2024-10-08T18:08:06.507524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+----------------------------------+------------------+\n",
      "| geo_area|authentic_per_area|amount_reviews_with_positive_words| %positive_reviews|\n",
      "+---------+------------------+----------------------------------+------------------+\n",
      "|SouthEast|             72058|                              1653| 2.293985400649477|\n",
      "|NorthWest|              5495|                               141|2.5659690627843497|\n",
      "|SouthWest|             22815|                               610|2.6736795967565197|\n",
      "|NorthEast|             46060|                              1337|2.9027355623100304|\n",
      "+---------+------------------+----------------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#positive_authentic_reviews.show(10)\n",
    "positive_authentic_reviews_for_geo = positive_authentic_reviews.join(business_with_geo, on=\"business_id\")\n",
    "\n",
    "# We then group by geo_area column and count them.\n",
    "positive_authentic_reviews_grouped = positive_authentic_reviews_for_geo.groupBy(\"geo_area\").count()\n",
    "positive_authentic_reviews_grouped = positive_authentic_reviews_grouped.withColumnRenamed\\\n",
    "(\"count\",\"amount_reviews_with_positive_words\")\n",
    "\n",
    "#negative_authentic_reviews_grouped.show(10)\n",
    "\n",
    "#Join with the table over geographical locations\n",
    "overall_geo_area_and_positive_words = positive_authentic_reviews_grouped.join(business_geo_percent, on=\"geo_area\")\n",
    "\n",
    "overall_geo_area_and_positive_words = overall_geo_area_and_positive_words.withColumn(\"%positive_reviews\",\\\n",
    "                                                                         (F.col(\"amount_reviews_with_positive_words\")\\\n",
    "                                                                         /F.col(\"authentic_per_area\"))*100)\n",
    "\n",
    "overall_geo_area_and_positive_words.select(\"geo_area\",\"authentic_per_area\",\"amount_reviews_with_positive_words\",\"%positive_reviews\").orderBy(\"%positive_reviews\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e7c1d5",
   "metadata": {},
   "source": [
    "### Task 3.3: Building a Rating Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7143ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
